# Potthast, M., KoÌˆpsel, S., Stein, B., & Hagen, M. (2016, March). Clickbait detection. In European Conference on Information Retrieval (pp. 810-817). Springer International Publishing.

- 215 features
  - Three categories
    - Teaser message
      - Three categories
        - Basic text statistics
          - Bag-of-words features
          - Twitter-specific
          - Automatically generated image tags (Imagga tagging service)
          - Sentiment polarity (Stanford NLP Library)
          - Readability
          - Terrier stop word list and Dale-Chall list of easy words
          - Quantity of contradictions and punctuation use
          - Length statistics
        - Dictionary features
          - Checking if a tweet contains a word from a given dictionary of specific words or phrases
          - Dictionaries obtained from Gianotto
            - Common clickbait phrases
            - Clickbait patterns in the form of regular expressions
          - All 182 General Inquirer dictionaries
    - Linked web page
      - Bag-of-words features
      - Readability and length of the main content when extracted with Boilerpipe
    - Meta information
      - The tweet's sender
      - Whether media (e.g., an image or a video) has been attached to a tweet
      - Whether a tweet has been retweeted
      - Part of day in which the tweet was sent (i.e., morning, afternoon, evening, night)
- Random forest classifier
- Takeaways
  - Clickbaity BuzzFeed articles contain a cardinal number in their title, and 85% of the article titles started with that number
    - The same titles have strong nouns and adjectives to convey authority and sensationalism
    - The main articles consistently achieve easy readability according to the Gunning fog index
  - Phoricity
    - Discourse deixis
      - Using keywords like "This" in "This news will blow your mind."
  - They use Gianotto's rule set premises as features and as a basline for evaluation
    - http://downworthy.snipe.net/
  - Evaluation
    - Randomly split corpus into datasets for training and testing at a 2:1 training-test ratio
    - To avoid overfitting, they discard all features that have non-trivial weights in less than 1% of the training dataset only
      - Kept features in Table 2, but many individual features from the bag-of-words feature types were discarded
    - Compared logistic regression, naive Bayes, and random forest in Weka 3.7 using default parameters
    - Evaluate performance of all features combined, each feature category on its own, and each individual feature (type) in isolation
      - Results shown in Table 2
    - The character n-gram features and the word 1-gram feature appear to contribute most to performance
      - Character n-grams are known to capture writing style
    - Sentiment analysis alone appears to be insufficient to detect clickbait, but in feature combinations it does possess some predictive power
